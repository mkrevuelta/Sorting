# Computational complexity and the "Big O" notation

## Introduction

The [computational complexity](http://en.wikipedia.org/wiki/Computational_complexity_theory) of an algorithm is a measure of the time and space (in memory) required for its execution, depending on the size of the problem.

The ["Big O" notation](http://en.wikipedia.org/wiki/Big_O_notation) is used for describing the behaviour of these two parameters (time and space) when the size of the problem changes.

The documentation of this project uses the "Big O" notation to describe and compare the different sorting algorithms. This page provides the informal background required to understand this notation.

**To be continued...**


<br><br>
<a href='../LICENSE'><img src='../img/cc_by_88x31.png' alt='Creative Commons License' /></a><br>
**Author:** [Mart√≠n Knoblauch Revuelta](http://www.mkrevuelta.com/en/about-me/)<br>
This work is licensed under a [Creative Commons Attribution 3.0 Unported License](../LICENSE)</a>

